{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO1GJ_-kbqCB"
   },
   "source": [
    "![Add a relevant banner image here](path_to_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efdDK3eIbqCC"
   },
   "source": [
    "# **Flatiron Data Science Capstone Project 1: US Traffic Accidents**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6ge5WeibqCC"
   },
   "source": [
    "## Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyLQUFdUbqCC"
   },
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5b80PSYbqCC"
   },
   "source": [
    "The US Department of Transportation (DOT) is concerned about the number of traffic accidents across the US and wants to develop strategies to reduce accidents and improve road safety.\n",
    "\n",
    "For the Department of Transportation (DOT), understanding and reducing traffic accidents is a critical mission that directly impacts public safety, economic costs, and quality of life across the United States.\n",
    "\n",
    "This analysis matters from a stakeholder and business perspective:\n",
    "\n",
    "-Economic Impact: Traffic accidents cost billions annually in medical expenses, property damage, and lost productivity, making even small reductions highly valuable.\n",
    "\n",
    "-Public Safety: As a leading cause of injury and death, reducing traffic accidents directly fulfills DOT's core mandate to protect citizens.\n",
    "\n",
    "-Infrastructure Prioritization: Data analysis enables strategic allocation of limited infrastructure improvement budgets to highest-risk areas.\n",
    "\n",
    "-Policy Development: Accident data informs new safety regulations and provides metrics to evaluate existing programs' effectiveness.\n",
    "\n",
    "-Stakeholder Accountability: Comprehensive analysis demonstrates evidence-based decision-making to Congress, local governments, and the public.\n",
    "\n",
    "-Cross-Agency Collaboration: Shared data insights can align accident reduction efforts across DOT, law enforcement, and emergency services.\n",
    "\n",
    "-Technology Integration: Understanding accident patterns guides how emerging vehicle technologies should be regulated to maximize safety benefits.\n",
    "\n",
    "This project supports DOT's mission by translating complex accident data into actionable insights. By identifying key patterns and risk factors, it empowers smarter infractstructure investment, better regulation and ultimately safer roads for all.\n",
    "\n",
    "Project Objectives:\n",
    "1. Identify accident hotspots: This analysis will determine when and where accidents most frequently occur.  Patterns such as time of day, day of week, season, and geographic location will be examined to determine of there are critical hotspots and time periods that may warrant intervention.\n",
    "2. Analyze environmental risk factors: This analysis will determine how weather conditions correlate with accident rates. Factors such as visibility, precipitation, temperature and other environmental variables will be examined to assess their impact on driver behavior and road conditions. The goal is to determine if certain weather conditions should trigger early warning notifications to drivers.\n",
    "3. Compare Urban and Rural Accident Patterns: This analysis will assess accident patterns between urban and rural settings. These different environments likely present distinct challenges and risk factors. Understanding these differences can inform the development of location-specific safety strategies.\n",
    "\n",
    "By successfully identifying accident hotspots, environmental risk factors, and urban/rural accident patterns, DOT can execute initiatives to address these issues and fulfill its mission to the public."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clc1XoCJbqCC"
   },
   "source": [
    "## Data Understanding\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14751,
     "status": "ok",
     "timestamp": 1751868392582,
     "user": {
      "displayName": "Joseph Lee",
      "userId": "03614348732629050745"
     },
     "user_tz": 420
    },
    "id": "yDRt10wpcpz7",
    "outputId": "fbc84979-db04-4e82-9a4d-df6405dda52c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1456,
     "status": "ok",
     "timestamp": 1751868402022,
     "user": {
      "displayName": "Joseph Lee",
      "userId": "03614348732629050745"
     },
     "user_tz": 420
    },
    "id": "f2YRw_gAbqCC"
   },
   "outputs": [],
   "source": [
    "# Load relevant imports here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels as stats\n",
    "import scipy\n",
    "\n",
    "# column definitions in Onedrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O7y2MgDLbqCC"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# df = pd.read_csv('/content/drive/MyDrive/US_Accidents_March23.csv')\n",
    "\n",
    "# PC path to the CSV file\n",
    "df = pd.read_csv(r\"C:\\Users\\jtlee\\OneDrive\\Documents\\Flatiron Schoolwork\\DS_11 Capstone\\Project 1 US Traffic Accidents\\US_Accidents_March23.csv\")\n",
    "\n",
    "# add laptop path to CSV file\n",
    "# df = pd.readcsv(r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of US accidents dataset: (7728394, 46)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 46 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   ID                     object \n",
      " 1   Source                 object \n",
      " 2   Severity               int64  \n",
      " 3   Start_Time             object \n",
      " 4   End_Time               object \n",
      " 5   Start_Lat              float64\n",
      " 6   Start_Lng              float64\n",
      " 7   End_Lat                float64\n",
      " 8   End_Lng                float64\n",
      " 9   Distance(mi)           float64\n",
      " 10  Description            object \n",
      " 11  Street                 object \n",
      " 12  City                   object \n",
      " 13  County                 object \n",
      " 14  State                  object \n",
      " 15  Zipcode                object \n",
      " 16  Country                object \n",
      " 17  Timezone               object \n",
      " 18  Airport_Code           object \n",
      " 19  Weather_Timestamp      object \n",
      " 20  Temperature(F)         float64\n",
      " 21  Wind_Chill(F)          float64\n",
      " 22  Humidity(%)            float64\n",
      " 23  Pressure(in)           float64\n",
      " 24  Visibility(mi)         float64\n",
      " 25  Wind_Direction         object \n",
      " 26  Wind_Speed(mph)        float64\n",
      " 27  Precipitation(in)      float64\n",
      " 28  Weather_Condition      object \n",
      " 29  Amenity                bool   \n",
      " 30  Bump                   bool   \n",
      " 31  Crossing               bool   \n",
      " 32  Give_Way               bool   \n",
      " 33  Junction               bool   \n",
      " 34  No_Exit                bool   \n",
      " 35  Railway                bool   \n",
      " 36  Roundabout             bool   \n",
      " 37  Station                bool   \n",
      " 38  Stop                   bool   \n",
      " 39  Traffic_Calming        bool   \n",
      " 40  Traffic_Signal         bool   \n",
      " 41  Turning_Loop           bool   \n",
      " 42  Sunrise_Sunset         object \n",
      " 43  Civil_Twilight         object \n",
      " 44  Nautical_Twilight      object \n",
      " 45  Astronomical_Twilight  object \n",
      "dtypes: bool(13), float64(12), int64(1), object(20)\n",
      "memory usage: 2.0+ GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nShape of US accidents dataset: {df.shape}\\n\")     # (rows, columns)\n",
    "\n",
    "df.info()  # DataFrame info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print preview of the dataframe:\n",
      "\n",
      "    ID   Source  Severity           Start_Time             End_Time  \\\n",
      "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
      "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
      "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
      "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
      "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
      "\n",
      "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
      "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
      "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
      "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
      "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
      "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
      "\n",
      "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
      "0   False  False           False          False        False          Night   \n",
      "1   False  False           False          False        False          Night   \n",
      "2   False  False           False           True        False          Night   \n",
      "3   False  False           False          False        False          Night   \n",
      "4   False  False           False           True        False            Day   \n",
      "\n",
      "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
      "0          Night             Night                 Night  \n",
      "1          Night             Night                   Day  \n",
      "2          Night               Day                   Day  \n",
      "3            Day               Day                   Day  \n",
      "4            Day               Day                   Day  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Print preview of the dataframe:\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                             0\n",
      "Source                         0\n",
      "Severity                       0\n",
      "Start_Time                     0\n",
      "End_Time                       0\n",
      "Start_Lat                      0\n",
      "Start_Lng                      0\n",
      "End_Lat                  3402762\n",
      "End_Lng                  3402762\n",
      "Distance(mi)                   0\n",
      "Description                    5\n",
      "Street                     10869\n",
      "City                         253\n",
      "County                         0\n",
      "State                          0\n",
      "Zipcode                     1915\n",
      "Country                        0\n",
      "Timezone                    7808\n",
      "Airport_Code               22635\n",
      "Weather_Timestamp         120228\n",
      "Temperature(F)            163853\n",
      "Wind_Chill(F)            1999019\n",
      "Humidity(%)               174144\n",
      "Pressure(in)              140679\n",
      "Visibility(mi)            177098\n",
      "Wind_Direction            175206\n",
      "Wind_Speed(mph)           571233\n",
      "Precipitation(in)        2203586\n",
      "Weather_Condition         173459\n",
      "Amenity                        0\n",
      "Bump                           0\n",
      "Crossing                       0\n",
      "Give_Way                       0\n",
      "Junction                       0\n",
      "No_Exit                        0\n",
      "Railway                        0\n",
      "Roundabout                     0\n",
      "Station                        0\n",
      "Stop                           0\n",
      "Traffic_Calming                0\n",
      "Traffic_Signal                 0\n",
      "Turning_Loop                   0\n",
      "Sunrise_Sunset             23246\n",
      "Civil_Twilight             23246\n",
      "Nautical_Twilight          23246\n",
      "Astronomical_Twilight      23246\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1 accident hotspot analysis\n",
    "\n",
    "Will look at patterns such as time of day, day of week, season, and geogrpahic location\n",
    "\n",
    "Start time can be used to determine time of day, day of week, and season.\n",
    "Geographic location will be determined using state, county and zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of hotspots df: (7728394, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7728394 entries, 0 to 7728393\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   ID          object\n",
      " 1   Start_Time  object\n",
      " 2   City        object\n",
      " 3   County      object\n",
      " 4   State       object\n",
      " 5   Zipcode     object\n",
      "dtypes: object(6)\n",
      "memory usage: 353.8+ MB\n",
      "None\n",
      "ID               0\n",
      "Start_Time       0\n",
      "City           253\n",
      "County           0\n",
      "State            0\n",
      "Zipcode       1915\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe for objective 1 accident hotspot analysis\n",
    "\n",
    "df_hotspots = df[['ID', 'Start_Time', 'City', 'County', 'State', 'Zipcode', ]].copy()\n",
    "\n",
    "print(f\"Shape of hotspots df: {df_hotspots.shape}\")\n",
    "print(df_hotspots.info())\n",
    "print(df_hotspots.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "253 missing City and 1,915 zipcode values out of 7.7 million data points is not significant. They will be dropped, as they shouldn't hurt the analysis at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique states: ['AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\n",
      "\n",
      "Number of states included in the dataset: 49\n"
     ]
    }
   ],
   "source": [
    "# check for unique states and their counts\n",
    "print(f\"\\nUnique states: {sorted(df['State'].unique())}\")\n",
    "print(f\"\\nNumber of states included in the dataset: {df['State'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there are only 49 states included in this US accidents dataset. Upon further examination, DC has been included, and Alaska and Hawaii are not present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKrFXnZzbqCC"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1 Accident hotpot analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7726228, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing City and Zipcode values\n",
    "df_hotspots.dropna(subset=['City', 'Zipcode'], inplace=True)\n",
    "df_hotspots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID          Start_Time          City      County State     Zipcode  \\\n",
      "0  A-1 2016-02-08 05:46:00        Dayton  Montgomery    OH       45424   \n",
      "1  A-2 2016-02-08 06:07:59  Reynoldsburg    Franklin    OH  43068-3402   \n",
      "2  A-3 2016-02-08 06:49:27  Williamsburg    Clermont    OH       45176   \n",
      "3  A-4 2016-02-08 07:23:34        Dayton  Montgomery    OH       45417   \n",
      "4  A-5 2016-02-08 07:39:07        Dayton  Montgomery    OH       45459   \n",
      "\n",
      "   Time_of_day Day_of_week  \n",
      "0            5      Monday  \n",
      "1            6      Monday  \n",
      "2            6      Monday  \n",
      "3            7      Monday  \n",
      "4            7      Monday  \n"
     ]
    }
   ],
   "source": [
    "# take Start Time column and convert to datetime format\n",
    "df_hotspots['Start_Time'] = pd.to_datetime(df_hotspots['Start_Time'], format='mixed', errors='coerce')\n",
    "\n",
    "# create new column for time of day (hour of the day)\n",
    "df_hotspots['Time_of_day'] = df_hotspots['Start_Time'].dt.hour\n",
    "\n",
    "# create new column for day of week\n",
    "# df_hotspots['day_of_week'] = df_hotspots['Start_Time'].dt.dayofweek\n",
    "\n",
    "# convert day of week to actual day name\n",
    "df_hotspots['Day_of_week'] = df_hotspots['Start_Time'].dt.day_name()\n",
    "\n",
    "print(df_hotspots.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID          Start_Time          City      County State     Zipcode  \\\n",
      "0  A-1 2016-02-08 05:46:00        Dayton  Montgomery    OH       45424   \n",
      "1  A-2 2016-02-08 06:07:59  Reynoldsburg    Franklin    OH  43068-3402   \n",
      "2  A-3 2016-02-08 06:49:27  Williamsburg    Clermont    OH       45176   \n",
      "3  A-4 2016-02-08 07:23:34        Dayton  Montgomery    OH       45417   \n",
      "4  A-5 2016-02-08 07:39:07        Dayton  Montgomery    OH       45459   \n",
      "\n",
      "   Time_of_day Day_of_week  Season  \n",
      "0            5      Monday  Winter  \n",
      "1            6      Monday  Winter  \n",
      "2            6      Monday  Winter  \n",
      "3            7      Monday  Winter  \n",
      "4            7      Monday  Winter  \n"
     ]
    }
   ],
   "source": [
    "# define a function to get the season based on the month\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "    \n",
    "df_hotspots['Season'] = df_hotspots['Start_Time'].dt.month.apply(get_season)\n",
    "\n",
    "print(df_hotspots.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Miami              186917\n",
      "Houston            169609\n",
      "Los Angeles        156491\n",
      "Charlotte          138652\n",
      "Dallas             130939\n",
      "Orlando            109733\n",
      "Austin              97359\n",
      "Raleigh             86079\n",
      "Nashville           72930\n",
      "Baton Rouge         71588\n",
      "Atlanta             68186\n",
      "Sacramento          66264\n",
      "San Diego           55504\n",
      "Phoenix             53974\n",
      "Minneapolis         51488\n",
      "Richmond            48845\n",
      "Oklahoma City       46092\n",
      "Jacksonville        42447\n",
      "Tucson              39304\n",
      "Columbia            38178\n",
      "San Antonio         37961\n",
      "Greenville          37802\n",
      "Saint Paul          37383\n",
      "Seattle             36564\n",
      "Portland            35399\n",
      "San Jose            34536\n",
      "Indianapolis        33219\n",
      "Chicago             32035\n",
      "Tampa               31193\n",
      "Denver              30557\n",
      "Kansas City         30107\n",
      "Tulsa               28880\n",
      "Riverside           27410\n",
      "New Orleans         27354\n",
      "Bronx               27297\n",
      "Rochester           26866\n",
      "Fort Lauderdale     26205\n",
      "Detroit             24865\n",
      "Grand Rapids        24764\n",
      "Oakland             24674\n",
      "Dayton              24572\n",
      "Brooklyn            22311\n",
      "Columbus            22216\n",
      "San Bernardino      21990\n",
      "New York            21699\n",
      "Omaha               21573\n",
      "Bakersfield         21390\n",
      "Corona              21363\n",
      "Anaheim             21293\n",
      "Long Beach          21146\n",
      "Name: count, dtype: int64\n",
      "County\n",
      "Los Angeles         526851\n",
      "Miami-Dade          251601\n",
      "Orange              241275\n",
      "Harris              181196\n",
      "Dallas              157024\n",
      "Mecklenburg         147265\n",
      "Montgomery          136788\n",
      "Wake                117890\n",
      "San Bernardino      109631\n",
      "Travis              107881\n",
      "Maricopa            106737\n",
      "San Diego           104165\n",
      "Alameda              98553\n",
      "Davidson             96580\n",
      "Sacramento           95377\n",
      "Riverside            88248\n",
      "East Baton Rouge     75260\n",
      "Santa Clara          70482\n",
      "Cook                 65599\n",
      "Marion               59498\n",
      "Hennepin             58978\n",
      "Jefferson            58158\n",
      "Greenville           57242\n",
      "King                 56934\n",
      "Fulton               55958\n",
      "Hillsborough         55581\n",
      "Broward              53865\n",
      "Lake                 53624\n",
      "Contra Costa         51338\n",
      "Oklahoma             46058\n",
      "Wayne                43262\n",
      "Jackson              42480\n",
      "Genesee              42163\n",
      "Duval                41728\n",
      "Queens               41480\n",
      "Pinellas             41387\n",
      "Douglas              40675\n",
      "Pima                 40433\n",
      "Monroe               39771\n",
      "Richland             39686\n",
      "Spartanburg          39581\n",
      "Hamilton             38991\n",
      "Bexar                38636\n",
      "Salt Lake            38615\n",
      "Lee                  38504\n",
      "Westchester          38224\n",
      "Middlesex            38143\n",
      "Washington           38017\n",
      "Kern                 37614\n",
      "Suffolk              37179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check of consistency of spelling in top 50 city and county columns\n",
    "print(df['City'].value_counts().head(50))\n",
    "print(df['County'].value_counts().head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipcode\n",
      "27610    12907\n",
      "33186    11952\n",
      "32819    11894\n",
      "91761    11455\n",
      "70808    10971\n",
      "28205    10797\n",
      "91706    10556\n",
      "28208    10411\n",
      "27604    10185\n",
      "37211     9931\n",
      "92407     9925\n",
      "28216     9832\n",
      "33169     9809\n",
      "70816     9762\n",
      "92507     9548\n",
      "70802     9381\n",
      "28217     9354\n",
      "90022     9333\n",
      "33155     9225\n",
      "29615     9168\n",
      "90023     9153\n",
      "29210     8965\n",
      "32837     8817\n",
      "33168     8817\n",
      "28273     8792\n",
      "27603     8727\n",
      "37013     8641\n",
      "70809     8415\n",
      "91748     8389\n",
      "27612     8226\n",
      "33150     8222\n",
      "37210     8142\n",
      "28262     8137\n",
      "75243     8083\n",
      "32839     8078\n",
      "37207     8009\n",
      "27606     7913\n",
      "78753     7870\n",
      "27616     7809\n",
      "90248     7724\n",
      "29223     7719\n",
      "91765     7695\n",
      "27529     7634\n",
      "90012     7565\n",
      "33157     7536\n",
      "92324     7515\n",
      "28206     7450\n",
      "32809     7407\n",
      "27609     7265\n",
      "33165     7200\n",
      "Name: count, dtype: int64\n",
      "['45424' '43068' '45176' ... '69120' '38614' '04231']\n"
     ]
    }
   ],
   "source": [
    "# extract just the first 5 digits of the Zipcode column\n",
    "# This is to ensure that the Zipcode column is in the correct format\n",
    "df_hotspots['Zipcode'] = df_hotspots['Zipcode'].astype(str).str.extract(r'^(\\d{5})')\n",
    "print(df_hotspots['Zipcode'].value_counts().head(50))\n",
    "print(df_hotspots['Zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID          Start_Time          City      County State Zipcode  \\\n",
      "0  A-1 2016-02-08 05:46:00        Dayton  Montgomery    OH   45424   \n",
      "1  A-2 2016-02-08 06:07:59  Reynoldsburg    Franklin    OH   43068   \n",
      "2  A-3 2016-02-08 06:49:27  Williamsburg    Clermont    OH   45176   \n",
      "3  A-4 2016-02-08 07:23:34        Dayton  Montgomery    OH   45417   \n",
      "4  A-5 2016-02-08 07:39:07        Dayton  Montgomery    OH   45459   \n",
      "\n",
      "   Time_of_day Day_of_week  Season  \n",
      "0            5      Monday  Winter  \n",
      "1            6      Monday  Winter  \n",
      "2            6      Monday  Winter  \n",
      "3            7      Monday  Winter  \n",
      "4            7      Monday  Winter  \n"
     ]
    }
   ],
   "source": [
    "print(df_hotspots.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID          Start_Time          City      County State Zipcode  \\\n",
      "0  A-1 2016-02-08 05:46:00        Dayton  Montgomery    OH   45424   \n",
      "1  A-2 2016-02-08 06:07:59  Reynoldsburg    Franklin    OH   43068   \n",
      "2  A-3 2016-02-08 06:49:27  Williamsburg    Clermont    OH   45176   \n",
      "3  A-4 2016-02-08 07:23:34        Dayton  Montgomery    OH   45417   \n",
      "4  A-5 2016-02-08 07:39:07        Dayton  Montgomery    OH   45459   \n",
      "\n",
      "   Time_of_day Day_of_week  Season Time_period  \n",
      "0            5      Monday  Winter  Late Night  \n",
      "1            6      Monday  Winter     Morning  \n",
      "2            6      Monday  Winter     Morning  \n",
      "3            7      Monday  Winter     Morning  \n",
      "4            7      Monday  Winter     Morning  \n"
     ]
    }
   ],
   "source": [
    "def convert_hour_to_period(hour):\n",
    "    if 0 <= hour < 6:\n",
    "        return 'Late Night'\n",
    "    elif 6 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "df_hotspots['Time_period'] = df_hotspots['Time_of_day'].apply(convert_hour_to_period)\n",
    "print(df_hotspots.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQBIXW0UbqCC"
   },
   "source": [
    "## Analysis\n",
    "\n",
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz5RLgt2bqCC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZVNWNWMbqCD"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "### Business Insight/Recommendation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5tbWAotbqCD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuWM8ooibqCD"
   },
   "source": [
    "### Business Insight/Recommendation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8o9pEkCJbqCD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwNpKS-GbqCD"
   },
   "source": [
    "### Business Insight/Recommendation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPcozzicbqCD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8uNU1wvbqCD"
   },
   "source": [
    "### Tableau Dashboard link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6iIwf-WbqCD"
   },
   "source": [
    "## Conclusion and Next Steps\n",
    "Text here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
